# GitLab CICD workflow definition with both CI and CD pipeline logic
.shared_runner_nonprod:
  tags: ["runner-nonprod"]

.shared_runner_prod:
  tags: ["runner-prod"]

image:
  name: python:3.8-slim

stages:
    - unit-testing
    - integration-testing
    - release-nonprod
    - release-prod

unit-testing:
  extends:
    - .shared_runner_dev
  stage: unit-testing
  only:
    refs:
      - pushes
  script:
    - echo "CI Job Stage - $CI_JOB_STAGE"
    - echo "Install dependencies"
    - export http_proxy=""
    - export https_proxy=""
    - pip install --upgrade pip
    - pip install -r unit-requirements.txt
    - pip install -e .
    - echo "Launching unit tests"
    - pytest tests/unit

integration-testing:
  extends:
    - .shared_runner_nonprod
  stage: integration-testing
  only:
    refs:
      - pushes
  variables:
    DEPLOYMENT_ENV: nonprod
    API_TOKEN_NONPROD: $API_TOKEN_NONPROD
    API_TOKEN_PROD: $API_TOKEN_PROD
  script:
    - echo "CI Job Stage - $CI_JOB_STAGE"
    - echo "Setup ~/.databrickscfg"
    - echo -e "[prod]\nhost = https://<>.cloud.databricks.com\ntoken = ${API_TOKEN_PROD} \njobs-api-version = 2.0\n\n[nonprod]\nhost = https://<>.cloud.databricks.com\ntoken = ${API_TOKEN_NONPROD} \njobs-api-version = 2.0\n" > ~/.databrickscfg
    - echo "Install dependencies"
    - export http_proxy=""
    - export https_proxy=""
    - apt-get update
    - apt-get install -y git # requirement for dbx
    - pip install -r unit-requirements.txt
    - pip install -e .
    - echo "Deploying integration tests to $DEPLOYMENT_ENV"
    - dbx deploy --deployment-file conf/deployment.yml --jobs=integration-test --files-only --environment=$DEPLOYMENT_ENV
    - echo "Launching integration tests in $DEPLOYMENT_ENV"
    - dbx launch --job=integration-test --as-run-submit --trace --environment=$DEPLOYMENT_ENV

release-nonprod:
  extends:
    - .shared_runner_nonprod # using nonprod for testing
  stage: release-nonprod
  variables:
    DEPLOYMENT_ENV: nonprod
    API_TOKEN_NONPROD: $API_TOKEN_NONPROD
    API_TOKEN_PROD: $API_TOKEN_PROD
  only:
    refs:
      - merge_requests
      - main
  script:
    - echo "CI Job Stage - $CI_JOB_STAGE"
    - echo "Setup ~/.databrickscfg"
    - echo -e "[prod]\nhost = https://<>.cloud.databricks.com\ntoken = ${API_TOKEN_PROD} \njobs-api-version = 2.0\n\n[nonprod]\nhost = https://<>.cloud.databricks.com\ntoken = ${API_TOKEN_NONPROD} \njobs-api-version = 2.0\n" > ~/.databrickscfg
    - echo "Install dependencies"
    - export http_proxy=""
    - export https_proxy=""
    - apt-get update
    - apt-get install -y git # requirement for dbx
    - pip install -r unit-requirements.txt
    - pip install -e .
    - echo "Deploying model-train Job to $DEPLOYMENT_ENV"
    - dbx deploy --deployment-file conf/deployment.yml --jobs=model-train --environment=$DEPLOYMENT_ENV
